{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN-GeneracionTexto.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9Uk_DNw5983j","colab_type":"text"},"source":["# Generación de Texto usando una  Recurrent Neuronal Network del tipo RNN básico, LSTM o GRU\n","Basado en https://www.tensorflow.org/tutorials/text/text_generation"]},{"cell_type":"markdown","metadata":{"id":"7Mjqn0ta-JmL","colab_type":"text"},"source":["1) Cargar las librerías:"]},{"cell_type":"code","metadata":{"id":"MAgWSjOw-JwI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"65626cc0-aaa1-445e-c295-470ca14dfa97","executionInfo":{"status":"ok","timestamp":1586612781566,"user_tz":180,"elapsed":2541,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","\n","import numpy as np\n","import os\n","import time\n","\n","from google.colab import files \n","import io\n","\n","print(\"Librerías cargadas\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Librerías cargadas\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gGFu1mdg-N5w","colab_type":"text"},"source":["2) Cargar el texto base a procesar:"]},{"cell_type":"markdown","metadata":{"id":"2qQQ8NIJ2WMm","colab_type":"text"},"source":["*   desde Google Drive:\n","\n","*Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.*"]},{"cell_type":"code","metadata":{"id":"etDVW375lv5u","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# directorio local en Google Drive\n","path = 'gdrive/My Drive/IA/demoRNN'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1h1PnwK-Q1Y","colab_type":"code","colab":{}},"source":["# levanta el archivo de texto del Drive para procesar\n","text = open(\"\".join([path, \"/RNN Cantata del adelantado Don Rodrigo Diaz de Carreras - preparado.txt\"]), 'rb').read().decode(encoding='utf-8')\n","\n","print(\"Archivo cargado\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PTNhvulD2ghz","colab_type":"text"},"source":["\n","\n","*   Subiendolo desde el disco local:\n"]},{"cell_type":"code","metadata":{"id":"rQ8HX1u_2kUj","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":74},"outputId":"765671a2-beae-4b04-afc9-1e92a3fb529c","executionInfo":{"status":"ok","timestamp":1586612797692,"user_tz":180,"elapsed":10686,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# Seleccionar y subir archivo de texto del disco local al Drive para procesar\n","uploaded = files.upload()\n"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-c59ab312-661b-4805-85a2-3ad269b088ac\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-c59ab312-661b-4805-85a2-3ad269b088ac\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving RNN proverbios.txt to RNN proverbios.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P1HFigCN2og8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8d82bf05-e041-44e8-c391-aed31e48235f","executionInfo":{"status":"ok","timestamp":1586612800994,"user_tz":180,"elapsed":980,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# carga el texto a procesar y lo codifica en formato py2\n","text = str(str(uploaded[list(uploaded.keys())[0]]))\n","\n","print(\"Archivo cargado\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Archivo cargado\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s0vV2Fgv2pWd","colab_type":"text"},"source":["Una vez cargado el archivo muestra sus estadísticas:"]},{"cell_type":"code","metadata":{"id":"ZF8IjXCv3Dg7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"87fd0095-1479-4766-d889-f2ab58547845","executionInfo":{"status":"ok","timestamp":1586612806631,"user_tz":180,"elapsed":1305,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# length of text is the number of characters in it\n","print ('Tamaño total del texto: {} caracteres'.format(len(text)))\n","\n","# muestra los primeros 250 caracteres del texto\n","print(\"Ejemplo: \\n\", text[:250])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Tamaño total del texto: 59988 caracteres\n","Ejemplo: \n"," b'\\xef\\xbb\\xbfa caballo regalado no se le mira el colmillo\\r\\na caballo regalado no se le miran los dientes\\r\\na cada chancho le llega su san marti\\r\\na confesion de parte relevo de prueba\\r\\nalli donde fueres haz lo que vieres\\r\\ndondequiera que fue\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mIgEntMT-ZbB","colab_type":"text"},"source":["3) Preparar el texto base a procesar:"]},{"cell_type":"code","metadata":{"id":"jvaOGfdL-gnP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"outputId":"c0cc9ac7-772b-4a78-f116-8ce8de01bc26","executionInfo":{"status":"ok","timestamp":1586612810586,"user_tz":180,"elapsed":1381,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# The unique characters in the file\n","vocab = sorted(set(text))\n","print ('{} caracteres distintos detectados'.format(len(vocab)))\n","\n","# Creating a mapping from unique characters to indices\n","char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","text_as_int = np.array([char2idx[c] for c in text])\n","\n","print('{')\n","for char,_ in zip(char2idx, range(20)):\n","    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n","print('  ...\\n}')\n","\n","# Muestra ejemplo de cómo se mapean los caracteres a valores numéricos\n","print ('{} <-------- > {}'.format(repr(text[:13]), text_as_int[:13]))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["40 caracteres distintos detectados\n","{\n","  ' ' :   0,\n","  '\"' :   1,\n","  \"'\" :   2,\n","  '/' :   3,\n","  '0' :   4,\n","  '1' :   5,\n","  '2' :   6,\n","  '3' :   7,\n","  '8' :   8,\n","  '9' :   9,\n","  '?' :  10,\n","  '[' :  11,\n","  '\\\\':  12,\n","  ']' :  13,\n","  'a' :  14,\n","  'b' :  15,\n","  'c' :  16,\n","  'd' :  17,\n","  'e' :  18,\n","  'f' :  19,\n","  ...\n","}\n","\"b'\\\\xef\\\\xbb\\\\xb\" <-------- > [15  2 12 37 18 19 12 37 15 15 12 37 15]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sdDNAjcy-ov6","colab_type":"text"},"source":["4) Dividir en datos de entrenamiento y prueba, para ello divide el texto en secuencias donde \n","- la secuencia de la posición 0 a [seq_length] se considera de entrada, y \n","- la secuencia de la posición  [seq_length+1] al final es la de salida"]},{"cell_type":"code","metadata":{"id":"Jph0s63Q-s55","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"e4cf0099-5705-4c13-8b38-75e83ecd8725","executionInfo":{"status":"ok","timestamp":1586612821679,"user_tz":180,"elapsed":73,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# determinar el largo máximo de la secuencia\n","if ((len(text)//101)<1000):\n","  seq_length = 50\n","else:\n","  seq_length = 100\n","examples_per_epoch = len(text)//(seq_length+1)\n","print(\"Largo de secuencias: \", seq_length)\n","print(\"Ejemplos por época: \", examples_per_epoch)\n","\n","# genera un vector de caracteres\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n","\n","#for i in char_dataset.take(5):\n","#  print(idx2char[i.numpy()])\n","\n","# procesa para generar las secuencias el largo deseado\n","sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","# muestra ejemplo\n","for item in sequences.take(5):\n","  print(repr(''.join(idx2char[item.numpy()])))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["\"b'\\\\xef\\\\xbb\\\\xbfa caballo regalado no se le mira el c\"\n","'olmillo\\\\r\\\\na caballo regalado no se le miran los di'\n","'entes\\\\r\\\\na cada chancho le llega su san marti\\\\r\\\\na '\n","'confesion de parte relevo de prueba\\\\r\\\\nalli donde f'\n","'ueres haz lo que vieres\\\\r\\\\ndondequiera que fueres h'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-1q_vpDF-yCQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"c332f5ab-6591-4835-efc1-7d6ca53eb1fc","executionInfo":{"status":"ok","timestamp":1586612825841,"user_tz":180,"elapsed":934,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# genera las secuencias de entrada y salida\n","def split_input_target(chunk):\n","    input_text = chunk[:-1]\n","    target_text = chunk[1:]\n","    return input_text, target_text\n","\n","datasetSeq = sequences.map(split_input_target)\n","\n","print(\"DatasetSeq: \", datasetSeq, \"\\n\")\n","\n","# muestra ejemplo\n","for input_example, target_example in  datasetSeq.take(2):\n","  print ('Texto de Entrada: ', repr(''.join(idx2char[input_example.numpy()])))\n","  print ('Texto  de Salida:', repr(''.join(idx2char[target_example.numpy()])))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["DatasetSeq:  <MapDataset shapes: ((50,), (50,)), types: (tf.int64, tf.int64)> \n","\n","Texto de Entrada:  \"b'\\\\xef\\\\xbb\\\\xbfa caballo regalado no se le mira el \"\n","Texto  de Salida: \"'\\\\xef\\\\xbb\\\\xbfa caballo regalado no se le mira el c\"\n","Texto de Entrada:  'olmillo\\\\r\\\\na caballo regalado no se le miran los d'\n","Texto  de Salida: 'lmillo\\\\r\\\\na caballo regalado no se le miran los di'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yyj9bjy8-2Qp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"a542b11e-d499-428f-af38-1ca652f1846a","executionInfo":{"status":"ok","timestamp":1586612829856,"user_tz":180,"elapsed":951,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# muestra entrada y salida por cada caracter\n","for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n","    print(\"Step {:4d}\".format(i))\n","    print(\"  Entrada: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n","    print(\"  Salida Esperada: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Step    0\n","  Entrada: 28 ('o')\n","  Salida Esperada: 25 ('l')\n","Step    1\n","  Entrada: 25 ('l')\n","  Salida Esperada: 26 ('m')\n","Step    2\n","  Entrada: 26 ('m')\n","  Salida Esperada: 22 ('i')\n","Step    3\n","  Entrada: 22 ('i')\n","  Salida Esperada: 25 ('l')\n","Step    4\n","  Entrada: 25 ('l')\n","  Salida Esperada: 25 ('l')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jpktfg15-48J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"fe4eba38-1196-4ef1-f6f7-09281bc5f0fe","executionInfo":{"status":"ok","timestamp":1586612833149,"user_tz":180,"elapsed":1045,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# genera 'batch' de secuencias que se van a procesar en el entrenamiento\n","\n","# Batch size\n","BATCH_SIZE = 64\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 100000\n","\n","dataset = datasetSeq.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","\n","print(\"Dataset: \", dataset, \"\\n\")\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Dataset:  <BatchDataset shapes: ((64, 50), (64, 50)), types: (tf.int64, tf.int64)> \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Opx54HBy-8Cw","colab_type":"text"},"source":["5) Especificar el modelo de la RNN:"]},{"cell_type":"markdown","metadata":{"id":"C7BUCvHFZ98j","colab_type":"text"},"source":["\n","*   Modelo RNN básico:\n"]},{"cell_type":"code","metadata":{"id":"1Duu1enMaToP","colab_type":"code","colab":{}},"source":["# define el modelo RNN\n","def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.SimpleRNN(rnn_units,\n","                        return_sequences=True,\n","                        stateful=True,\n","                        recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)\n","  ])\n","  return model\n","\n","print(\"Modelo RNN definido\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-a5FkGLNaAO7","colab_type":"text"},"source":["\n","*   Modelo LSTM:\n"]},{"cell_type":"code","metadata":{"id":"0ioYuuvlasGi","colab_type":"code","colab":{}},"source":["# define el modelo LSTM\n","def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.LSTM(rnn_units,\n","                        return_sequences=True,\n","                        stateful=True,\n","                        recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)\n","  ])\n","  return model\n","\n","print(\"Modelo LSTM definido\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gp0xn1voaASR","colab_type":"text"},"source":["\n","*   Modelo GRU:\n"]},{"cell_type":"code","metadata":{"id":"sbKkhXKXa0Md","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c6672c2d-8d0f-4263-cb62-d80487fbfb72","executionInfo":{"status":"ok","timestamp":1586612839307,"user_tz":180,"elapsed":1617,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# define el modelo RNN\n","def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.GRU(rnn_units,\n","                        return_sequences=True,\n","                        stateful=True,\n","                        recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)\n","  ])\n","  return model\n","\n","print(\"Modelo GRU definido\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Modelo GRU definido\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lO4KR88BaOJB","colab_type":"text"},"source":["Luego de seleccionado el modelo a armar, lo genera:"]},{"cell_type":"code","metadata":{"id":"4XQ7Af5j-8Lo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"outputId":"65deed87-5bcd-4c31-c27d-363b7ab152b7","executionInfo":{"status":"ok","timestamp":1586612848777,"user_tz":180,"elapsed":7080,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# Length of the vocabulary in chars\n","vocab_size = len(vocab)\n","\n","# The embedding dimension\n","embedding_dim = 256\n","\n","# Number of RNN units\n","rnn_units = 1024\n","\n","# genera el modelo\n","model = build_model(\n","  vocab_size = len(vocab),\n","  embedding_dim=embedding_dim,\n","  rnn_units=rnn_units,\n","  batch_size=BATCH_SIZE)\n","\n","model.summary()\n","\n","# prepara variables auxiliares para el entrenamiento  de la RNN\n","for input_example_batch, target_example_batch in dataset.take(1):\n","  example_batch_predictions = model(input_example_batch)\n","  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n","\n","sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n","\n","# compila el modelo para el entrenamiento  de la RNN\n","def loss(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n","\n","example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n","print(\"Forma vector predicción: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n","\n","model.compile(optimizer='adam', loss=loss)\n","\n","print(\"\\nModelo generado\", model)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (64, None, 256)           10240     \n","_________________________________________________________________\n","gru (GRU)                    (64, None, 1024)          3938304   \n","_________________________________________________________________\n","dense (Dense)                (64, None, 40)            41000     \n","=================================================================\n","Total params: 3,989,544\n","Trainable params: 3,989,544\n","Non-trainable params: 0\n","_________________________________________________________________\n","(64, 50, 40) # (batch_size, sequence_length, vocab_size)\n","Forma vector predicción:  (64, 50, 40)  # (batch_size, sequence_length, vocab_size)\n","scalar_loss:       3.6881292\n","\n","Modelo generado <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f21b05b1160>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c2Q1uWbU_XqH","colab_type":"text"},"source":["6) Entrenar la RNN:"]},{"cell_type":"code","metadata":{"id":"LCwiXCwO_jLz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c2ece4f6-5fe1-4ca8-daaf-dd11cbc6ffa0","executionInfo":{"status":"ok","timestamp":1586612851241,"user_tz":180,"elapsed":906,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# define donde se a almacenar la información de checkpoints\n","\n","# Directory where the checkpoints will be saved\n","checkpoint_dir = './checkpoints/RNN_training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)\n","\n","print(\"Checkpoints grabados en \", checkpoint_dir)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Checkpoints grabados en  ./checkpoints/RNN_training_checkpoints\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xcC4sTBq_q46","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b2b1e20b-6479-4446-9af5-e6870af22cab","executionInfo":{"status":"ok","timestamp":1586612947580,"user_tz":180,"elapsed":95149,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# ejecutar el entrenamiento (poner antes en GPU)\n","EPOCHS = 100\n","history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","18/18 [==============================] - 1s 42ms/step - loss: 3.5716\n","Epoch 2/100\n","18/18 [==============================] - 1s 38ms/step - loss: 2.7876\n","Epoch 3/100\n","18/18 [==============================] - 1s 38ms/step - loss: 2.3411\n","Epoch 4/100\n","18/18 [==============================] - 1s 42ms/step - loss: 2.0999\n","Epoch 5/100\n","18/18 [==============================] - 1s 38ms/step - loss: 1.9962\n","Epoch 6/100\n","18/18 [==============================] - 1s 38ms/step - loss: 1.9365\n","Epoch 7/100\n","18/18 [==============================] - 1s 39ms/step - loss: 1.8977\n","Epoch 8/100\n","18/18 [==============================] - 1s 38ms/step - loss: 1.8634\n","Epoch 9/100\n","18/18 [==============================] - 1s 39ms/step - loss: 1.8315\n","Epoch 10/100\n","18/18 [==============================] - 1s 40ms/step - loss: 1.8025\n","Epoch 11/100\n","18/18 [==============================] - 1s 39ms/step - loss: 1.7733\n","Epoch 12/100\n","18/18 [==============================] - 1s 38ms/step - loss: 1.7452\n","Epoch 13/100\n","18/18 [==============================] - 1s 39ms/step - loss: 1.7120\n","Epoch 14/100\n","18/18 [==============================] - 1s 39ms/step - loss: 1.6868\n","Epoch 15/100\n","18/18 [==============================] - 1s 38ms/step - loss: 1.6551\n","Epoch 16/100\n","18/18 [==============================] - 1s 39ms/step - loss: 1.6312\n","Epoch 17/100\n","18/18 [==============================] - 1s 38ms/step - loss: 1.5982\n","Epoch 18/100\n","18/18 [==============================] - 1s 38ms/step - loss: 1.5596\n","Epoch 19/100\n","18/18 [==============================] - 1s 40ms/step - loss: 1.5257\n","Epoch 20/100\n","18/18 [==============================] - 1s 42ms/step - loss: 1.4896\n","Epoch 21/100\n","18/18 [==============================] - 1s 39ms/step - loss: 1.4504\n","Epoch 22/100\n","18/18 [==============================] - 1s 38ms/step - loss: 1.4069\n","Epoch 23/100\n","18/18 [==============================] - 1s 39ms/step - loss: 1.3668\n","Epoch 24/100\n","18/18 [==============================] - 1s 54ms/step - loss: 1.3174\n","Epoch 25/100\n","18/18 [==============================] - 1s 39ms/step - loss: 1.2747\n","Epoch 26/100\n","18/18 [==============================] - 1s 38ms/step - loss: 1.2263\n","Epoch 27/100\n","18/18 [==============================] - 1s 39ms/step - loss: 1.1767\n","Epoch 28/100\n","18/18 [==============================] - 1s 38ms/step - loss: 1.1261\n","Epoch 29/100\n","18/18 [==============================] - 1s 40ms/step - loss: 1.0677\n","Epoch 30/100\n","18/18 [==============================] - 1s 63ms/step - loss: 1.0143\n","Epoch 31/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.9605\n","Epoch 32/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.9080\n","Epoch 33/100\n","18/18 [==============================] - 1s 39ms/step - loss: 0.8545\n","Epoch 34/100\n","18/18 [==============================] - 1s 39ms/step - loss: 0.8001\n","Epoch 35/100\n","18/18 [==============================] - 1s 40ms/step - loss: 0.7505\n","Epoch 36/100\n","18/18 [==============================] - 1s 56ms/step - loss: 0.7059\n","Epoch 37/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.6543\n","Epoch 38/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.6138\n","Epoch 39/100\n","18/18 [==============================] - 1s 40ms/step - loss: 0.5773\n","Epoch 40/100\n","18/18 [==============================] - 1s 39ms/step - loss: 0.5451\n","Epoch 41/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.5133\n","Epoch 42/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.4865\n","Epoch 43/100\n","18/18 [==============================] - 1s 40ms/step - loss: 0.4645\n","Epoch 44/100\n","18/18 [==============================] - 1s 40ms/step - loss: 0.4386\n","Epoch 45/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.4270\n","Epoch 46/100\n","18/18 [==============================] - 1s 37ms/step - loss: 0.4095\n","Epoch 47/100\n","18/18 [==============================] - 1s 41ms/step - loss: 0.3978\n","Epoch 48/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.3860\n","Epoch 49/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.3740\n","Epoch 50/100\n","18/18 [==============================] - 1s 39ms/step - loss: 0.3579\n","Epoch 51/100\n","18/18 [==============================] - 1s 43ms/step - loss: 0.3530\n","Epoch 52/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.3472\n","Epoch 53/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.3390\n","Epoch 54/100\n","18/18 [==============================] - 1s 53ms/step - loss: 0.3290\n","Epoch 55/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.3204\n","Epoch 56/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.3191\n","Epoch 57/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.3116\n","Epoch 58/100\n","18/18 [==============================] - 1s 39ms/step - loss: 0.3044\n","Epoch 59/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.3022\n","Epoch 60/100\n","18/18 [==============================] - 1s 39ms/step - loss: 0.2979\n","Epoch 61/100\n","18/18 [==============================] - 1s 40ms/step - loss: 0.2952\n","Epoch 62/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2860\n","Epoch 63/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2851\n","Epoch 64/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2825\n","Epoch 65/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2843\n","Epoch 66/100\n","18/18 [==============================] - 1s 69ms/step - loss: 0.2748\n","Epoch 67/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2682\n","Epoch 68/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2703\n","Epoch 69/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2680\n","Epoch 70/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2616\n","Epoch 71/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2603\n","Epoch 72/100\n","18/18 [==============================] - 1s 53ms/step - loss: 0.2602\n","Epoch 73/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2576\n","Epoch 74/100\n","18/18 [==============================] - 1s 40ms/step - loss: 0.2537\n","Epoch 75/100\n","18/18 [==============================] - 1s 41ms/step - loss: 0.2513\n","Epoch 76/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2499\n","Epoch 77/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2487\n","Epoch 78/100\n","18/18 [==============================] - 1s 40ms/step - loss: 0.2453\n","Epoch 79/100\n","18/18 [==============================] - 1s 42ms/step - loss: 0.2465\n","Epoch 80/100\n","18/18 [==============================] - 1s 40ms/step - loss: 0.2457\n","Epoch 81/100\n","18/18 [==============================] - 1s 41ms/step - loss: 0.2418\n","Epoch 82/100\n","18/18 [==============================] - 1s 41ms/step - loss: 0.2384\n","Epoch 83/100\n","18/18 [==============================] - 1s 41ms/step - loss: 0.2325\n","Epoch 84/100\n","18/18 [==============================] - 5s 258ms/step - loss: 0.2310\n","Epoch 85/100\n","18/18 [==============================] - 1s 40ms/step - loss: 0.2305\n","Epoch 86/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2320\n","Epoch 87/100\n","18/18 [==============================] - 1s 39ms/step - loss: 0.2288\n","Epoch 88/100\n","18/18 [==============================] - 1s 40ms/step - loss: 0.2297\n","Epoch 89/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2272\n","Epoch 90/100\n","18/18 [==============================] - 1s 39ms/step - loss: 0.2233\n","Epoch 91/100\n","18/18 [==============================] - 1s 42ms/step - loss: 0.2243\n","Epoch 92/100\n","18/18 [==============================] - 4s 197ms/step - loss: 0.2219\n","Epoch 93/100\n","18/18 [==============================] - 1s 48ms/step - loss: 0.2237\n","Epoch 94/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2199\n","Epoch 95/100\n","18/18 [==============================] - 1s 43ms/step - loss: 0.2189\n","Epoch 96/100\n","18/18 [==============================] - 1s 60ms/step - loss: 0.2206\n","Epoch 97/100\n","18/18 [==============================] - 1s 39ms/step - loss: 0.2162\n","Epoch 98/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2176\n","Epoch 99/100\n","18/18 [==============================] - 1s 38ms/step - loss: 0.2158\n","Epoch 100/100\n","18/18 [==============================] - 1s 40ms/step - loss: 0.2144\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6j_vf8-1_xWM","colab_type":"text"},"source":["7) Probar la RNN entrenada:"]},{"cell_type":"code","metadata":{"id":"gy6c8Ney82k6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"e70eb2b8-468c-442d-b6ae-a49eeeec3816","executionInfo":{"status":"ok","timestamp":1586612956523,"user_tz":180,"elapsed":977,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# recupera la información del último checkpoint\n","tf.train.latest_checkpoint(checkpoint_dir)\n","\n","modelPred = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","modelPred.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","modelPred.build(tf.TensorShape([1, None]))\n","\n","modelPred.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (1, None, 256)            10240     \n","_________________________________________________________________\n","gru_1 (GRU)                  (1, None, 1024)           3938304   \n","_________________________________________________________________\n","dense_1 (Dense)              (1, None, 40)             41000     \n","=================================================================\n","Total params: 3,989,544\n","Trainable params: 3,989,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S9RSE-cm_5OK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"outputId":"9019708c-3fb4-4613-f96f-576ce50cd280","executionInfo":{"status":"ok","timestamp":1586612971655,"user_tz":180,"elapsed":5584,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# define función auxiliar para devolver predicción de texto\n","\n","def generate_text(model, start_string):\n","  # Evaluation step (generating text using the learned model)\n","\n","  # Number of characters to generate\n","  num_generate = 1000\n","\n","  # Converting our start string to numbers (vectorizing)\n","  input_eval = [char2idx[s] for s in start_string]\n","  input_eval = tf.expand_dims(input_eval, 0)\n","\n","  # Empty string to store our results\n","  text_generated = []\n","\n","  # Low temperatures results in more predictable text.\n","  # Higher temperatures results in more surprising text.\n","  # Experiment to find the best setting.\n","  temperature = 0.3 # 1.0\n","\n","  # Here batch size == 1\n","  model.reset_states()\n","  for i in range(num_generate):\n","      predictions = model(input_eval)\n","      # remove the batch dimension\n","      predictions = tf.squeeze(predictions, 0)\n","\n","      # using a categorical distribution to predict the word returned by the model\n","      predictions = predictions / temperature\n","      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","\n","      # We pass the predicted word as the next input to the model\n","      # along with the previous hidden state\n","      input_eval = tf.expand_dims([predicted_id], 0)\n","\n","      text_generated.append(idx2char[predicted_id])\n","\n","  return (start_string + ''.join(text_generated))\n","\n","# ejecuta el modeo usando como entrada un texto  (para ejemplo de MASTROPIERO)\n","print(\"\\n\\n--------------------------------------------------------------------\\n\\n\")\n","print(generate_text(modelPred, start_string=u\"a\"))\n","print(\"\\n\\n--------------------------------------------------------------------\\n\\n\")\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["\n","\n","--------------------------------------------------------------------\n","\n","\n","a sucia se lava en casa\\r\\nla sonrisa abre puertas\\r\\nes dificil que el tiempo no amanse\\r\\nno hay mal que dure cien a\\xc3\\xb1os\\r\\nno hay mal que cien a\\xc3\\xb1os dure\\r\\nno hay mal que dure cien a\\xc3\\xb1os\\r\\nno hay mal que cien a\\xc3\\xb1os dure\\r\\nno hay mal que dure cien a\\xc3\\xb1os\\r\\nno hay mal que cien a\\xc3\\xb1os dure\\r\\nno hay mal que dure cien a\\xc3\\xb1os dure ni bien que a ellos ature\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dure que galope que canse\\r\\nmas vale trote que dur\n","\n","\n","--------------------------------------------------------------------\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xlnoBnACoAc9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"outputId":"a0110741-bfed-49e9-e53a-7382e8cfd408","executionInfo":{"status":"ok","timestamp":1586613003924,"user_tz":180,"elapsed":5531,"user":{"displayName":"pgp tensorflow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0DLxJFRAnupgefM52bgK9stGcSNcWMKG3Xacm=s64","userId":"04809512947468796788"}}},"source":["# ejecuta el modeo usando como entrada un texto  (para ejemplo de MASTROPIERO)\n","print(\"\\n\\n--------------------------------------------------------------------\\n\\n\")\n","print(generate_text(modelPred, start_string=u\"no\"))\n","print(\"\\n\\n--------------------------------------------------------------------\\n\\n\")\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["\n","\n","--------------------------------------------------------------------\n","\n","\n","no se va lontano\\r\\npiensa mal y estaras acertado\\r\\nes camo para el otro como sandia en un carro\\r\\nde un cojo\\r\\ncae mas pronto el embustero que el agujero del mate\\r\\nmas viejo que andar a pie\\r\\nmas viejo que el agujero del mate\\r\\nmas viejo que andar a pie\\r\\nes un pecho fri\\r\\nes una iglesia abandonada no saca otro\\r\\ncon un clavo se saca otro\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a otro clavo\\r\\nun clavo saca a o\n","\n","\n","--------------------------------------------------------------------\n","\n","\n"],"name":"stdout"}]}]}